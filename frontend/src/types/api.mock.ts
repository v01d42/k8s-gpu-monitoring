// Mock API responses for backend endpoints
import type { ApiResponse, GPUMetrics, GPUProcess } from "./api";

export const mockGpuMetrics: ApiResponse<GPUMetrics[]> = {
  success: true,
  message: "GPU metrics retrieved successfully",
  data: [
    {
      node_name: "gpu14",
      gpu_index: 0,
      gpu_name: "NVIDIA A100",
      gpu_utilization: 85.2,
      gpu_memory_used: 32,
      gpu_memory_total: 40,
      memory_free: 8,
      temperature: 70.5,
      cpu_utilization: 45.2,
      memory_utilization: 62.8,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu14",
      gpu_index: 1,
      gpu_name: "NVIDIA A100",
      gpu_utilization: 90.0,
      gpu_memory_used: 36,
      gpu_memory_total: 40,
      memory_free: 4,
      temperature: 72.0,
      cpu_utilization: 52.1,
      memory_utilization: 68.3,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu15",
      gpu_index: 0,
      gpu_name: "NVIDIA V100",
      gpu_utilization: 55.5,
      gpu_memory_used: 10,
      gpu_memory_total: 16,
      memory_free: 6,
      temperature: 68.0,
      cpu_utilization: 28.5,
      memory_utilization: 42.1,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu15",
      gpu_index: 1,
      gpu_name: "NVIDIA V100",
      gpu_utilization: 60.1,
      gpu_memory_used: 12,
      gpu_memory_total: 16,
      memory_free: 4,
      temperature: 65.0,
      cpu_utilization: 35.7,
      memory_utilization: 48.9,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu16",
      gpu_index: 0,
      gpu_name: "NVIDIA A100",
      gpu_utilization: 78.3,
      gpu_memory_used: 30,
      gpu_memory_total: 40,
      memory_free: 10,
      temperature: 69.5,
      cpu_utilization: 41.3,
      memory_utilization: 55.6,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu16",
      gpu_index: 1,
      gpu_name: "NVIDIA A100",
      gpu_utilization: 92.7,
      gpu_memory_used: 38,
      gpu_memory_total: 40,
      memory_free: 2,
      temperature: 74.8,
      cpu_utilization: 58.9,
      memory_utilization: 72.4,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu17",
      gpu_index: 0,
      gpu_name: "NVIDIA RTX 4090",
      gpu_utilization: 95.4,
      gpu_memory_used: 22,
      gpu_memory_total: 24,
      memory_free: 2,
      temperature: 78.2,
      cpu_utilization: 68.4,
      memory_utilization: 81.2,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu17",
      gpu_index: 1,
      gpu_name: "NVIDIA RTX 4090",
      gpu_utilization: 67.8,
      gpu_memory_used: 16,
      gpu_memory_total: 24,
      memory_free: 8,
      temperature: 69.1,
      cpu_utilization: 38.2,
      memory_utilization: 51.7,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu18",
      gpu_index: 0,
      gpu_name: "NVIDIA H100",
      gpu_utilization: 88.9,
      gpu_memory_used: 68,
      gpu_memory_total: 80,
      memory_free: 12,
      temperature: 72.4,
      cpu_utilization: 55.8,
      memory_utilization: 70.1,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu18",
      gpu_index: 1,
      gpu_name: "NVIDIA H100",
      gpu_utilization: 42.3,
      gpu_memory_used: 28,
      gpu_memory_total: 80,
      memory_free: 52,
      temperature: 61.7,
      cpu_utilization: 22.4,
      memory_utilization: 35.2,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu19",
      gpu_index: 0,
      gpu_name: "NVIDIA V100",
      gpu_utilization: 73.5,
      gpu_memory_used: 12,
      gpu_memory_total: 16,
      memory_free: 4,
      temperature: 71.2,
      cpu_utilization: 48.3,
      memory_utilization: 60.8,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu19",
      gpu_index: 1,
      gpu_name: "NVIDIA V100",
      gpu_utilization: 29.8,
      gpu_memory_used: 4,
      gpu_memory_total: 16,
      memory_free: 12,
      temperature: 54.6,
      cpu_utilization: 15.2,
      memory_utilization: 28.5,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu20",
      gpu_index: 0,
      gpu_name: "NVIDIA A40",
      gpu_utilization: 82.1,
      gpu_memory_used: 38,
      gpu_memory_total: 48,
      memory_free: 10,
      temperature: 69.5,
      cpu_utilization: 52.7,
      memory_utilization: 65.3,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu20",
      gpu_index: 1,
      gpu_name: "NVIDIA A40",
      gpu_utilization: 14.7,
      gpu_memory_used: 4,
      gpu_memory_total: 48,
      memory_free: 44,
      temperature: 48.2,
      cpu_utilization: 8.5,
      memory_utilization: 18.2,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu21",
      gpu_index: 0,
      gpu_name: "NVIDIA RTX 3090",
      gpu_utilization: 99.1,
      gpu_memory_used: 23,
      gpu_memory_total: 24,
      memory_free: 1,
      temperature: 80.5,
      cpu_utilization: 75.3,
      memory_utilization: 88.6,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu22",
      gpu_index: 0,
      gpu_name: "NVIDIA A100",
      gpu_utilization: 12.5,
      gpu_memory_used: 5,
      gpu_memory_total: 40,
      memory_free: 35,
      temperature: 45.3,
      cpu_utilization: 6.8,
      memory_utilization: 15.4,
      timestamp: "2025-07-26T12:00:00Z",
    },
  ],
};

export const mockGPUProcesses: ApiResponse<GPUProcess[]> = {
  success: true,
  message: "GPU processes retrieved successfully",
  data: [
    {
      node_name: "gpu14",
      gpu_index: 0,
      pid: 1234,
      process_name: "python",
      user: "alice",
      command: "python train.py",
      gpu_memory: 1024,
      timestamp: "2024-01-01T12:00:00Z",
    },
    {
      node_name: "gpu14",
      gpu_index: 1,
      pid: 5678,
      process_name: "jupyter",
      user: "bob",
      command: "jupyter notebook",
      gpu_memory: 512,
      timestamp: "2024-01-01T12:00:00Z",
    },
    {
      node_name: "gpu15",
      gpu_index: 0,
      pid: 4321,
      process_name: "cuda_app",
      user: "carol",
      command: "./cuda_app",
      gpu_memory: 2048,
      timestamp: "2024-01-01T12:00:00Z",
    },
  ],
};

export const mockHealthz: ApiResponse = {
  success: true,
  message: "Service is healthy",
  data: {
    status: "healthy",
    timestamp: "2025-07-26T12:00:00Z",
    version: "1.0.0",
  },
};
